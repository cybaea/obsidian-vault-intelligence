import{_ as o,c as i,o as t,ae as n}from"./chunks/framework.DKf8Joaa.js";const u=JSON.parse('{"title":"Web Worker Embedding Implementation","description":"","frontmatter":{},"headers":[],"relativePath":"docs/web-worker-embedding.md","filePath":"docs/web-worker-embedding.md"}'),a={name:"docs/web-worker-embedding.md"};function r(s,e,d,l,c,h){return t(),i("div",null,[...e[0]||(e[0]=[n(`<h1 id="web-worker-embedding-implementation" tabindex="-1">Web Worker Embedding Implementation <a class="header-anchor" href="#web-worker-embedding-implementation" aria-label="Permalink to &quot;Web Worker Embedding Implementation&quot;">​</a></h1><p>This document provides a technical overview of how local embeddings are implemented in Vault Intelligence using <code>@xenova/transformers</code> (Transformers.js) inside a Web Worker.</p><h2 id="overview-of-approach" tabindex="-1">Overview of Approach <a class="header-anchor" href="#overview-of-approach" aria-label="Permalink to &quot;Overview of Approach&quot;">​</a></h2><p>The plugin uses a <strong>Web Worker</strong> to perform embedding generation off the main thread. This ensures that the Obsidian UI remains responsive even when processing large amounts of text or loading heavy models.</p><h3 id="architecture" tabindex="-1">Architecture <a class="header-anchor" href="#architecture" aria-label="Permalink to &quot;Architecture&quot;">​</a></h3><ul><li><strong><code>LocalEmbeddingService.ts</code></strong>: The main-thread service that manages the life cycle of the worker. It handles initialization, message queueing (via <code>pendingRequests</code> Map), and termination.</li><li><strong><code>embedding.worker.ts</code></strong>: The worker code that runs the Transformers.js pipeline.</li><li><strong><code>esbuild-plugin-inline-worker</code></strong>: Used to bundle and inline the worker script directly into <code>main.js</code>. This simplifies plugin distribution as it remains a single file.</li></ul><h2 id="key-technical-issues-overcome" tabindex="-1">Key Technical Issues Overcome <a class="header-anchor" href="#key-technical-issues-overcome" aria-label="Permalink to &quot;Key Technical Issues Overcome&quot;">​</a></h2><h3 id="_1-model2vec-missing-offsets-error" tabindex="-1">1. Model2Vec &quot;Missing Offsets&quot; Error <a class="header-anchor" href="#_1-model2vec-missing-offsets-error" aria-label="Permalink to &quot;1. Model2Vec &quot;Missing Offsets&quot; Error&quot;">​</a></h3><p>Model2Vec models (like <code>potion-base-8M</code>) require an <code>offsets</code> tensor that Transformers.js v2 does not automatically calculate for all model types.</p><ul><li><strong>Solution</strong>: Implemented a specialized <code>loadModel2Vec</code> function in the worker that manually calculates token offsets and passes them explicitly to the ONNX model.</li></ul><h3 id="_2-browser-environment-detection-in-esbuild" tabindex="-1">2. Browser Environment Detection in esbuild <a class="header-anchor" href="#_2-browser-environment-detection-in-esbuild" aria-label="Permalink to &quot;2. Browser Environment Detection in esbuild&quot;">​</a></h3><p>Transformers.js tries to detect if it&#39;s running in Node or Browser. Because Obsidian is an Electron app, it often incorrectly detects Node, leading to attempts to use <code>fs</code> which fail in a Worker.</p><ul><li><strong>Solution</strong>: Forced browser detection in <code>esbuild.config.mjs</code> by defining <code>process.release.name = &#39;browser&#39;</code> and <code>process.versions.node = &#39;false&#39;</code>.</li></ul><h3 id="_3-wasm-loading-cdn-paths" tabindex="-1">3. WASM Loading &amp; CDN Paths <a class="header-anchor" href="#_3-wasm-loading-cdn-paths" aria-label="Permalink to &quot;3. WASM Loading &amp; CDN Paths&quot;">​</a></h3><p>In a Web Worker, relative paths to WASM binaries often resolve incorrectly.</p><ul><li><strong>Solution</strong>: Hardcoded explicit CDN paths to <code>jsdelivr</code> for the ONNX Runtime WASM files to ensure consistent loading regardless of the user&#39;s filesystem structure.</li></ul><h3 id="_4-memory-management-oom-mitigation" tabindex="-1">4. Memory Management (OOM Mitigation) <a class="header-anchor" href="#_4-memory-management-oom-mitigation" aria-label="Permalink to &quot;4. Memory Management (OOM Mitigation)&quot;">​</a></h3><p>Loading large models or indexing thousands of files can pressure the 4GB V8 heap limit.</p><ul><li><strong>Solution</strong>: <ul><li>Implemented a <code>PipelineSingleton</code> in the worker to prevent multiple model instances.</li><li>Optimized <code>VectorStore.ts</code> with chunked buffer growth and automatic buffer shrinking.</li><li>Added aggressive cleanup (<code>worker.terminate()</code>) in the plugin&#39;s <code>onunload</code>.</li></ul></li></ul><h2 id="remaining-hacks-future-maintenance" tabindex="-1">Remaining &#39;Hacks&#39; &amp; Future Maintenance <a class="header-anchor" href="#remaining-hacks-future-maintenance" aria-label="Permalink to &quot;Remaining &#39;Hacks&#39; &amp; Future Maintenance&quot;">​</a></h2><ul><li><strong><code>mockPlugin</code> in esbuild</strong>: We mock Node modules (<code>fs</code>, <code>path</code>, etc.) to empty objects to satisfy esbuild. If Transformers.js adds new Node-specific dependencies, this list may need updating.</li><li><strong>Hardcoded CDN Versions</strong>: The WASM paths are pinned to <code>@2.17.2</code>. When upgrading <code>@xenova/transformers</code>, these URLs <strong>must</strong> be updated manually in <code>embedding.worker.ts</code>.</li><li><strong>Manual Offsets</strong>: The Model2Vec offset logic is a workaround for a limitation in Transformers.js v2. It should be re-evaluated when upgrading to v3 (Hugging Face Transformers.js).</li></ul><h2 id="debugging-and-testing" tabindex="-1">Debugging and Testing <a class="header-anchor" href="#debugging-and-testing" aria-label="Permalink to &quot;Debugging and Testing&quot;">​</a></h2><h3 id="connecting-to-the-worker" tabindex="-1">Connecting to the Worker <a class="header-anchor" href="#connecting-to-the-worker" aria-label="Permalink to &quot;Connecting to the Worker&quot;">​</a></h3><p>The worker runs in a separate thread. To see its logs:</p><ol><li>Launch Obsidian with remote debugging (use a random port number; we show 9223 below for example purposes):<div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Example for Flatpak</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">flatpak</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> md.obsidian.Obsidian</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --remote-debugging-port=9223</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --remote-allow-origins=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span></span></code></pre></div></li><li>In your browser, navigate to <code>http://localhost:9223</code>.</li><li>Find the entry labeled <code>blob:app://obsidian.md/...</code> (this is the worker).</li><li>Click it to open a dedicated DevTools window for the worker.</li></ol><h3 id="forcing-a-model-redownload" tabindex="-1">Forcing a Model Redownload <a class="header-anchor" href="#forcing-a-model-redownload" aria-label="Permalink to &quot;Forcing a Model Redownload&quot;">​</a></h3><p>If the model is corrupted or stuck, use the &quot;Force Redownload&quot; feature in settings. This clears the <code>transformers-cache</code> in Browser Cache Storage and restarts the worker.</p><h2 id="suggestions-for-next-steps" tabindex="-1">Suggestions for Next Steps <a class="header-anchor" href="#suggestions-for-next-steps" aria-label="Permalink to &quot;Suggestions for Next Steps&quot;">​</a></h2><ol><li><strong>Text Chunking</strong>: Currently, the entire document is sent as a single string. Implementing a chunking strategy (e.g., recursive character splitting or sentence-based) is critical for handling long notes without truncation.</li><li><strong>Quantization Support</strong>: Investigate why some specialized models fail to find <code>.onnx</code> quantized files on the CDN and provide better local fallbacks.</li><li><strong>Worker Pool</strong>: For very high-throughput indexing, consider a pool of 2 workers, though memory pressure must be carefully monitored.</li><li><strong>Progress Reporting</strong>: Add a progress callback from the worker to the main thread during the ONNX <code>model()</code> call for better UI feedback during long inferences.</li></ol>`,29)])])}const m=o(a,[["render",r]]);export{u as __pageData,m as default};
