import{_ as t,c as o,o as n,ae as i}from"./chunks/framework.DKf8Joaa.js";const d=JSON.parse('{"title":"üó∫Ô∏è Roadmap: Obsidian Vault Intelligence","description":"","frontmatter":{},"headers":[],"relativePath":"ROADMAP.md","filePath":"ROADMAP.md"}'),r={name:"ROADMAP.md"};function a(s,e,l,u,g,h){return n(),o("div",null,[...e[0]||(e[0]=[i('<h1 id="üó∫Ô∏è-roadmap-obsidian-vault-intelligence" tabindex="-1">üó∫Ô∏è Roadmap: Obsidian Vault Intelligence <a class="header-anchor" href="#üó∫Ô∏è-roadmap-obsidian-vault-intelligence" aria-label="Permalink to &quot;üó∫Ô∏è Roadmap: Obsidian Vault Intelligence&quot;">‚Äã</a></h1><blockquote><p><strong>Mission:</strong> To transform your Obsidian vault from passive storage into an active, intelligent partner that connects, verifies, and serves knowledge anywhere.</p></blockquote><p>This document outlines the strategic direction for Vault Intelligence. It is a living document that evolves as we learn from our users and the rapidly changing AI landscape.</p><hr><h2 id="üü¢-phase-1-the-open-foundation-current-focus" tabindex="-1">üü¢ Phase 1: The Open Foundation (Current Focus) <a class="header-anchor" href="#üü¢-phase-1-the-open-foundation-current-focus" aria-label="Permalink to &quot;üü¢ Phase 1: The Open Foundation (Current Focus)&quot;">‚Äã</a></h2><p><em><strong>Goal</strong>: Removing vendor lock-in and establishing a &quot;Batteries Included&quot; privacy-first experience.</em></p><p>We believe you shouldn&#39;t need a PhD or an expensive API key just to search your own notes, and you should always know exactly what data is leaving your machine.</p><ul><li><p>[ ] <strong>Universal &quot;Batteries Included&quot; Embeddings</strong></p><ul><li><strong>The Vision:</strong> Install the plugin and it <em>just works</em>. No API keys required for basic search.</li><li>[x] <strong>The Tech:</strong> We will bundle a lightweight, high-performance model (like <code>all-MiniLM-L6-v2</code>) directly into the plugin. It runs 100% locally on your device, ensuring total privacy and zero cost.</li><li>[ ] <strong>Performance:</strong> Upgrade to <strong>Transformers.js v3</strong> to leverage <strong>WebGPU</strong> for hardware-accelerated indexing (5x‚Äì10x speedup on compatible GPUs).</li><li>[ ] <strong>For Power Users:</strong> Support for connecting to local <strong>Ollama</strong> endpoints or other providers (OpenAI, Anthropic, Azure).</li></ul></li><li><p>[ ] <strong>The &quot;Active Graph&quot; Visualization</strong></p><ul><li><strong>The Vision:</strong> Move beyond the static &quot;spaghetti&quot; graph. When you view a note, see a focused, living constellation of related ideas.</li><li><strong>The Tech:</strong> An interactive sidebar graph that displays the active note at the center, orbiting related notes, and‚Äîcrucially‚Äîdrawing lines <em>between</em> those related notes to reveal hidden clusters of knowledge.</li></ul></li><li><p>[ ] <strong>&quot;Sovereign Intelligence&quot; (User Control &amp; Privacy)</strong></p><ul><li><strong>The Vision:</strong> The &quot;Right Model for the Right Task,&quot; transparently controlled by you.</li><li><strong>The Tech:</strong><ul><li><strong>Smart Routing:</strong> Automatically route simple searches to fast/cheap models (Gemini Flash) and complex reasoning to deep thinkers (Gemini Pro), with a clear UI showing <em>why</em> a model was chosen.</li><li><strong>Privacy Toggles:</strong> A &quot;Local-Only&quot; switch that instantly cuts off all cloud API calls, forcing the agent to rely solely on on-device embeddings and local LLMs (via Ollama) for sensitive work.</li><li><strong>Data Transparency:</strong> A log view showing exactly what text snippets are being sent to the cloud before they go.</li></ul></li></ul></li></ul><hr><h2 id="üü°-phase-2-breaking-silos-next-up" tabindex="-1">üü° Phase 2: Breaking Silos (Next Up) <a class="header-anchor" href="#üü°-phase-2-breaking-silos-next-up" aria-label="Permalink to &quot;üü° Phase 2: Breaking Silos (Next Up)&quot;">‚Äã</a></h2><p><em><strong>Goal</strong>: The Agent stops living in the sidebar. It works IN your editor and OUT with other apps.</em></p><p>A true partner doesn&#39;t just chat from the sidelines. It gets its hands dirty in your documents and connects your vault to the rest of your digital life.</p><ul><li><p>[ ] <strong>&quot;The Ghostwriter&quot; (Inline Co-Creation)</strong></p><ul><li><strong>The Vision:</strong> Break the &quot;Chat Sidebar&quot; silo. The agent works directly in your editor, acting as a collaborative writer.</li><li><strong>The Features:</strong><ul><li><strong>Inline Edit:</strong> Highlight a paragraph and ask: <em>&quot;Rewrite this to be more concise&quot;</em> or <em>&quot;Check this specific claim against my &#39;Project Alpha&#39; notes.&quot;</em> The agent edits the text in-place.</li><li><strong>Generative Insertion:</strong> Type <code>+++</code> (or a command) to trigger the agent to continue writing from your current cursor position, drawing context from the current file.</li><li><strong>File Creation:</strong> Ask the agent: <em>&quot;Create a new note for the &#39;Beta Launch&#39; meeting.&quot;</em> It generates the file, applies your templates, fills in the agenda based on previous notes, and opens it for you.</li></ul></li></ul></li><li><p>[ ] <strong>Model Context Protocol (MCP) Server</strong></p><ul><li><strong>The Vision:</strong> Use your vault notes inside <strong>Claude Desktop</strong>, <strong>Microsoft Copilot</strong>, or other AI tools.</li><li><strong>The Tech:</strong> Implement the <a href="https://modelcontextprotocol.io/" target="_blank" rel="noreferrer">MCP Standard</a> to turn this plugin into a local server. You can ask Claude: <em>&quot;Draft an email based on my &#39;Project Alpha&#39; notes,&quot;</em> and it will securely query your Obsidian vault to get the facts.</li></ul></li><li><p>[ ] <strong>Multi-Provider Reasoning</strong></p><ul><li><strong>The Vision:</strong> Freedom of choice. Use the best model for the job, regardless of who makes it.</li><li><strong>The Tech:</strong> An abstraction layer that allows the &quot;Research Agent&quot; to run on OpenAI, Anthropic, or local open-weights models, while preserving our advanced tool-use capabilities.</li></ul></li></ul><hr><h2 id="üü†-phase-3-visual-intelligence-the-excalidraw-stream" tabindex="-1">üü† Phase 3: Visual Intelligence (The &quot;Excalidraw&quot; Stream) <a class="header-anchor" href="#üü†-phase-3-visual-intelligence-the-excalidraw-stream" aria-label="Permalink to &quot;üü† Phase 3: Visual Intelligence (The &quot;Excalidraw&quot; Stream)&quot;">‚Äã</a></h2><p><em><strong>Goal</strong>: Treating diagrams, sketches, and spatial layouts as first-class citizens.</em></p><p>We recognize that for many users, &quot;drawing on the other side of the note&quot; is as important as writing. We will leverage the &quot;Hybrid&quot; Markdown format to make your diagrams intelligent.</p><ul><li><p>[ ] <strong>&quot;The Art Critic&quot; (Structure extraction)</strong></p><ul><li><strong>The Insight:</strong> Your hybrid notes contain the text (<code>## Text Elements</code>), but standard search tools cannot see the <em>relationships</em> (arrows, groups, flow) encoded in the drawing data.</li><li><strong>The Tech:</strong> A background process that parses the <code>compressed-json</code> block (or SVG), extracting the explicit connections (e.g., &quot;Element A -&gt; points to -&gt; Element B&quot;).</li><li><strong>The Result:</strong> The Agent understands the <em>process</em> you drew, not just the keywords.</li></ul></li><li><p>[ ] <strong>ExcaliBrain Graph Reasoning</strong></p><ul><li><strong>The Integration:</strong> Deep support for <a href="https://github.com/zsviczian/excalibrain" target="_blank" rel="noreferrer">ExcaliBrain</a>.</li><li><strong>The Feature:</strong> The agent will respect the explicit <code>parents</code>, <code>children</code>, and <code>friends</code> relationships defined in your ExcaliBrain frontmatter.</li></ul></li><li><p>[ ] <strong>&quot;Sketch-to-Structure&quot; (De-rendering)</strong></p><ul><li><strong>The Vision:</strong> Turn a messy whiteboard sketch into a clean note.</li><li><strong>The Use Case:</strong> Drag a hybrid <code>.md</code> file into the chat and ask: <em>&quot;Convert this visual logic flow into a Markdown checklist.&quot;</em></li></ul></li><li><p>[ ] <strong>&quot;Text-to-Diagram&quot; (Generative UI)</strong></p><ul><li><strong>The Vision:</strong> Ask the agent to <em>draw</em> for you.</li><li><strong>The Use Case:</strong> <em>&quot;Read my note on &#39;The Hero&#39;s Journey&#39; and append an Excalidraw diagram visualizing the cycle.&quot;</em> The agent writes the <code>compressed-json</code> block directly into your note, instantly rendering a diagram.</li></ul></li></ul><hr><h2 id="üîµ-phase-4-the-agentic-leap-future-horizons" tabindex="-1">üîµ Phase 4: The Agentic Leap (Future Horizons) <a class="header-anchor" href="#üîµ-phase-4-the-agentic-leap-future-horizons" aria-label="Permalink to &quot;üîµ Phase 4: The Agentic Leap (Future Horizons)&quot;">‚Äã</a></h2><p><em><strong>Goal</strong>: Moving from &quot;Questions&quot; to &quot;Tasks.&quot; The agent goes off, does work, and comes back.</em></p><ul><li><p>[ ] <strong>Voice Interface (Desktop First)</strong></p><ul><li><strong>The Vision:</strong> Talk to your vault while you work.</li><li><strong>The Use Case:</strong> A hands-free mode where you can ask questions or dictate notes using natural voice interactions (inspired by Readwise Reader). Ideal for accessibility and &quot;thinking out loud.&quot; Mobile support to follow.</li></ul></li><li><p>[ ] <strong>The &quot;Analyst&quot; (Multimodal Ingestion)</strong></p><ul><li><strong>The Vision:</strong> Don&#39;t just chat with text. Drag <strong>images, PDFs, and audio recordings</strong> into the chat.</li><li><strong>The Use Case:</strong> Drop a screenshot of a complex architectural diagram, and ask the agent to critique it against your existing design notes.</li></ul></li><li><p>[ ] <strong>Autonomous Research Reports</strong></p><ul><li><strong>The Vision:</strong> Give the agent a job, not a prompt.</li><li><strong>The Use Case:</strong> <em>&quot;Research the current state of Solid State Batteries.&quot;</em> The agent searches Google, reads results, cross-references your vault, and <strong>writes a new note</strong> with a synthesized report.</li></ul></li></ul><hr><h2 id="üü£-phase-5-blue-sky-experimental" tabindex="-1">üü£ Phase 5: Blue Sky (Experimental) <a class="header-anchor" href="#üü£-phase-5-blue-sky-experimental" aria-label="Permalink to &quot;üü£ Phase 5: Blue Sky (Experimental)&quot;">‚Äã</a></h2><p><em><strong>Goal</strong>: Novel interaction paradigms that define the future of PKM.</em></p><ul><li><p>[ ] <strong>&quot;Graph Gardener&quot; (Maintenance Agent)</strong></p><ul><li>A background agent that studies your vault&#39;s structure while you sleep, suggesting merges, splits, and bridges between isolated clusters of knowledge.</li></ul></li><li><p>[ ] <strong>Temporal Intelligence (&quot;Vault Evolution&quot;)</strong></p><ul><li>Analyze how your opinion on a topic has changed over time. <em>&quot;Summarize how my thinking on &#39;Remote Work&#39; has evolved since 2020.&quot;</em></li></ul></li></ul><hr><h2 id="üèóÔ∏è-technical-architecture-challenges" tabindex="-1">üèóÔ∏è Technical Architecture &amp; Challenges <a class="header-anchor" href="#üèóÔ∏è-technical-architecture-challenges" aria-label="Permalink to &quot;üèóÔ∏è Technical Architecture &amp; Challenges&quot;">‚Äã</a></h2><p>This section serves as a compass for architects and contributors, outlining the engineering hurdles we must clear to achieve the roadmap.</p><h3 id="_1-the-batteries-included-embedding-layer" tabindex="-1">1. The &quot;Batteries Included&quot; Embedding Layer <a class="header-anchor" href="#_1-the-batteries-included-embedding-layer" aria-label="Permalink to &quot;1. The &quot;Batteries Included&quot; Embedding Layer&quot;">‚Äã</a></h3><ul><li><strong>Constraint:</strong> Obsidian plugins run in an Electron environment. We cannot easily ship a Python backend.</li><li><strong>Strategy:</strong> Adopt <strong>ONNX Runtime Web</strong> or <strong>Transformers.js</strong> to run quantized models directly in the plugin&#39;s JavaScript runtime. <ul><li><strong>WebGPU:</strong> Transition to Transformers.js v3 to move inference from the CPU to the GPU, dramatically reducing indexing time for larger vaults.</li></ul></li><li><strong>Challenge:</strong> Balancing plugin bundle size (&lt;100MB target) vs. inference quality. We may need to implement a &quot;Download on Demand&quot; flow for model weights.</li></ul><h3 id="_2-editor-integration-ghostwriter" tabindex="-1">2. Editor Integration (&quot;Ghostwriter&quot;) <a class="header-anchor" href="#_2-editor-integration-ghostwriter" aria-label="Permalink to &quot;2. Editor Integration (&quot;Ghostwriter&quot;)&quot;">‚Äã</a></h3><ul><li><strong>Constraint:</strong> Safely editing the active markdown file while the user is typing (concurrency).</li><li><strong>Strategy:</strong> Leverage Obsidian&#39;s <code>Editor</code> transaction API to inject text or apply diffs without breaking the user&#39;s undo history.</li><li><strong>Inspiration:</strong> VS Code&#39;s Inline Chat API.</li></ul><h3 id="_3-model-context-protocol-mcp-implementation" tabindex="-1">3. Model Context Protocol (MCP) Implementation <a class="header-anchor" href="#_3-model-context-protocol-mcp-implementation" aria-label="Permalink to &quot;3. Model Context Protocol (MCP) Implementation&quot;">‚Äã</a></h3><ul><li><strong>Constraint:</strong> Exposing a local server from within Obsidian requires careful handling of network ports and security.</li><li><strong>Architecture:</strong> Spin up a local WebSocket/HTTP server on a configurable port (default <code>3000</code>) with token-based authentication.</li></ul><h3 id="_4-handling-excalidraw-hybrid-files" tabindex="-1">4. Handling Excalidraw Hybrid Files <a class="header-anchor" href="#_4-handling-excalidraw-hybrid-files" aria-label="Permalink to &quot;4. Handling Excalidraw Hybrid Files&quot;">‚Äã</a></h3><ul><li><strong>Format:</strong> Markdown with <code>compressed-json</code> (LZ-String) blocks.</li><li><strong>Strategy:</strong> Implement <code>LZString.decompressFromBase64()</code> to expand the diagram data for the AI, and compress the AI&#39;s JSON output for rendering. We extract structure (arrows/relationships) programmatically to augment the semantic search index.</li></ul><hr><h2 id="ü§ù-contributing" tabindex="-1">ü§ù Contributing <a class="header-anchor" href="#ü§ù-contributing" aria-label="Permalink to &quot;ü§ù Contributing&quot;">‚Äã</a></h2><p>This roadmap is not set in stone. We welcome community feedback!</p><ul><li><strong>Have an idea?</strong> Open a <a href="https://github.com/cybaea/obsidian-vault-intelligence/issues" target="_blank" rel="noreferrer">Feature Request</a>.</li><li><strong>Want to build it?</strong> Look for issues tagged <code>help wanted</code> or <code>good first issue</code>.</li></ul><hr><h1 id="üîÆ-research-horizons-2026" tabindex="-1">üîÆ Research Horizons (2026) <a class="header-anchor" href="#üîÆ-research-horizons-2026" aria-label="Permalink to &quot;üîÆ Research Horizons (2026)&quot;">‚Äã</a></h1><p><em>Experimental features targeting the new capabilities of Gemini 3, GPT-5, and Llama 4.</em></p><h2 id="_1-visual-vault-indexing-multimodal-rag" tabindex="-1">1. Visual Vault Indexing (Multimodal RAG) <a class="header-anchor" href="#_1-visual-vault-indexing-multimodal-rag" aria-label="Permalink to &quot;1. Visual Vault Indexing (Multimodal RAG)&quot;">‚Äã</a></h2><p><strong>Context:</strong> With <strong>Gemini 3&#39;s</strong> native multimodal context window and <strong>GPT-5&#39;s</strong> visual perception improvements, text-only RAG is now a legacy constraint.</p><ul><li><strong>Goal:</strong> Index every chart, whiteboard photo, and PDF diagram in the vault.</li><li><strong>Implementation:</strong><ul><li>Generate multimodal embeddings (using models like <strong>Nano Banana</strong> or <strong>LumiRAG</strong> architectures) for all image assets.</li><li>Allow users to query: <em>&quot;Look at the architecture diagram in the &#39;Q3 Review&#39; PDF and list the microservices.&quot;</em></li><li>Pass retrieved images directly to the Gemini 3 context window for analysis.</li></ul></li></ul><h2 id="_2-autonomous-verification-layers-corrective-rag" tabindex="-1">2. Autonomous Verification Layers (Corrective RAG) <a class="header-anchor" href="#_2-autonomous-verification-layers-corrective-rag" aria-label="Permalink to &quot;2. Autonomous Verification Layers (Corrective RAG)&quot;">‚Äã</a></h2><p><strong>Context:</strong> 2026 &quot;Agentic Workflow&quot; standards emphasize &quot;Bounded Autonomy&quot; and self-correction rather than blind generation.</p><ul><li><strong>Goal:</strong> The agent should verify its own retrieval quality before answering.</li><li><strong>Implementation:</strong><ul><li><strong>Confidence Check:</strong> If internal retrieval yields low similarity scores (e.g., outdated notes from 2023), the Agent automatically flags this gap.</li><li><strong>Active Grounding:</strong> Trigger a &quot;Deep Research&quot; sub-loop (similar to <strong>Gemini Deep Research Agent</strong>) to fetch up-to-date facts from the web, then synthesize them with the private notes.</li><li><strong>User Outcome:</strong> <em>&quot;Your notes on React are from 2023. I cross-referenced with the web, and the API has changed. Here is the comparison.&quot;</em></li></ul></li></ul><h2 id="_3-agent-os-orchestration-knowledge-runtimes" tabindex="-1">3. &quot;Agent OS&quot; Orchestration (Knowledge Runtimes) <a class="header-anchor" href="#_3-agent-os-orchestration-knowledge-runtimes" aria-label="Permalink to &quot;3. &quot;Agent OS&quot; Orchestration (Knowledge Runtimes)&quot;">‚Äã</a></h2><p><strong>Context:</strong> The industry is shifting from single-turn chats to &quot;Agent Orchestration Platforms&quot; (or Agent OS) where specialized agents handle specific domains.</p><ul><li><strong>Goal:</strong> Treat the Vault as a &quot;Knowledge Runtime&quot; rather than just a database.</li><li><strong>Implementation:</strong><ul><li><strong>Router Layer:</strong> A lightweight classifier (using <strong>Gemini 3 Flash</strong>) determines the user&#39;s intent: <em>Drafting, Debugging, or Fact-Checking</em>.</li><li><strong>Specialized Prompts:</strong><ul><li><em>Drafting Mode:</em> Retrieves stylistic matches from your previous essays.</li><li><em>Debugging Mode:</em> Prioritizes code snippets and StackOverflow-style notes.</li></ul></li><li><strong>Goal State:</strong> Maintain a &quot;Session Goal&quot; (e.g., &quot;Write a newsletter&quot;) that persists across multiple messages, reducing the need to re-prompt context.</li></ul></li></ul><h2 id="_4-federated-rag-privacy-silos" tabindex="-1">4. Federated RAG (Privacy &amp; Silos) <a class="header-anchor" href="#_4-federated-rag-privacy-silos" aria-label="Permalink to &quot;4. Federated RAG (Privacy &amp; Silos)&quot;">‚Äã</a></h2><p><strong>Context:</strong> With the rise of &quot;Enterprise Agentic Systems&quot; and governance controls, data often lives in decentralized, encrypted silos.</p><ul><li><strong>Goal:</strong> Connect to data <em>outside</em> the Obsidian vault without importing it.</li><li><strong>Implementation:</strong><ul><li><strong>External Connectors:</strong> Index local folders (e.g., Zotero libraries, local Code Repos, or &#39;Work&#39; folders) as separate &quot;Data Silos.&quot;</li><li><strong>Federated Retrieval:</strong> The Agent queries these external indices only when relevant, respecting the privacy boundaries of each source.</li></ul></li></ul>',56)])])}const m=t(r,[["render",a]]);export{d as __pageData,m as default};
