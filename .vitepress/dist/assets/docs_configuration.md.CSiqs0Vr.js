import{_ as e,c as o,o as l,ae as n}from"./chunks/framework.DKf8Joaa.js";const f=JSON.parse('{"title":"Configuration Guide","description":"","frontmatter":{},"headers":[],"relativePath":"docs/configuration.md","filePath":"docs/configuration.md"}'),r={name:"docs/configuration.md"};function s(a,t,d,i,g,c){return l(),o("div",null,[...t[0]||(t[0]=[n('<h1 id="configuration-guide" tabindex="-1">Configuration Guide <a class="header-anchor" href="#configuration-guide" aria-label="Permalink to &quot;Configuration Guide&quot;">‚Äã</a></h1><p>Vault Intelligence is designed to work out-of-the-box, but is highly customizable to suit different hardware, budgets, and workflows.</p><h2 id="üîë-connection" tabindex="-1">üîë Connection <a class="header-anchor" href="#üîë-connection" aria-label="Permalink to &quot;üîë Connection&quot;">‚Äã</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">Setting</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Google API key</strong></td><td style="text-align:left;"><code>None</code></td><td style="text-align:left;">Your secret key from <a href="https://aistudio.google.com/" target="_blank" rel="noreferrer">Google AI Studio</a>. Stored in plain text in your plugin settings. Required for all Gemini models and Gemini embeddings.</td></tr></tbody></table><h2 id="üß†-intelligence-chat" tabindex="-1">üß† Intelligence &amp; Chat <a class="header-anchor" href="#üß†-intelligence-chat" aria-label="Permalink to &quot;üß† Intelligence &amp; Chat&quot;">‚Äã</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">Setting</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Chat model</strong></td><td style="text-align:left;"><code>gemini-3-flash-preview</code></td><td style="text-align:left;">The main intelligence engine. <br>‚Ä¢ <strong>Flash:</strong> Best for speed and &quot;Agentic&quot; loops (tool use). <br>‚Ä¢ <strong>Pro:</strong> Best for deep reasoning or creative writing, but slower.</td></tr><tr><td style="text-align:left;"><strong>Context window budget</strong></td><td style="text-align:left;"><code>200,000</code></td><td style="text-align:left;">The maximum number of tokens (words/characters) the AI can consider at once. <br>‚ö†Ô∏è <strong>Note:</strong> This budget is also constrained by the inherent limit of your chosen <strong>Chat model</strong>. For example, while <code>gemini-3-flash-preview</code> supports up to 1 million tokens, other models may support much less. Setting this budget higher than the model&#39;s capacity will lead to errors. <br>‚Ä¢ <strong>Lower (e.g., 50k):</strong> Cheaper, faster, less comprehensive. <br>‚Ä¢ <strong>Higher:</strong> Reads more notes, but increases response time and costs.</td></tr><tr><td style="text-align:left;"><strong>Enable code execution</strong></td><td style="text-align:left;"><code>On</code></td><td style="text-align:left;">Turns on the <strong>Computational Solver</strong>. When enabled, the agent can write and execute Python code to solve math problems or analyze data.</td></tr><tr><td style="text-align:left;"><strong>Code model</strong></td><td style="text-align:left;"><code>gemini-3-flash-preview</code></td><td style="text-align:left;">The specialized model used for generating Python code. Only visible if code execution is enabled.</td></tr><tr><td style="text-align:left;"><strong>Max agent steps</strong></td><td style="text-align:left;"><code>5</code></td><td style="text-align:left;">Limits how many &quot;thoughts&quot; (loops) the agent can have before giving an answer. Prevents infinite loops.</td></tr></tbody></table><h2 id="üìê-vector-search-embeddings" tabindex="-1">üìê Vector Search &amp; Embeddings <a class="header-anchor" href="#üìê-vector-search-embeddings" aria-label="Permalink to &quot;üìê Vector Search &amp; Embeddings&quot;">‚Äã</a></h2><p>Choose how your document vectors are calculated and stored.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Setting</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Embedding provider</strong></td><td style="text-align:left;"><code>gemini</code></td><td style="text-align:left;"><strong>Google Gemini:</strong> Requires API key. Offloads work to Google. <br><strong>Local (Transformers.js):</strong> Runs on your CPU. Private and offline.</td></tr><tr><td style="text-align:left;"><strong>Embedding model</strong></td><td style="text-align:left;"><code>gemini-embedding-001</code></td><td style="text-align:left;"><strong>Gemini:</strong> <code>gemini-embedding-004</code> (latest) or <code>001</code>. <br><strong>Local Presets:</strong> <br>‚Ä¢ <strong>Small (Potion-8M):</strong> 256 dimensions. Extremely fast, ~15MB. <br>‚Ä¢ <strong>Balanced (BGE-Small):</strong> 384 dimensions. Good all-rounder, ~30MB. <br>‚Ä¢ <strong>Advanced (Nomic-Embed):</strong> 768 dimensions. Best quality, ~130MB. <br>‚Ä¢ <strong>Custom:</strong> Allows you to specify any ONNX-compatible HuggingFace ID.</td></tr><tr><td style="text-align:left;"><strong>Custom model ID</strong></td><td style="text-align:left;"><code>None</code></td><td style="text-align:left;">(Local + Custom only) The HuggingFace repository ID (e.g., <code>Xenova/all-MiniLM-L6-v2</code>). Use the <strong>Validate</strong> button to check compatibility and automatically detect dimensions.</td></tr><tr><td style="text-align:left;"><strong>Model dimensions</strong></td><td style="text-align:left;"><code>768</code></td><td style="text-align:left;">(Local + Custom only) The vector size for your custom model. Must be set correctly for search to function.</td></tr><tr><td style="text-align:left;"><strong>Model status</strong></td><td style="text-align:left;"><code>N/A</code></td><td style="text-align:left;">(Local only) Shows the current model being used by the worker and provides a <strong>Force re-download</strong> button to repair corrupted model files.</td></tr><tr><td style="text-align:left;"><strong>Re-index vault</strong></td><td style="text-align:left;"><code>N/A</code></td><td style="text-align:left;">Clear all saved vectors and re-scan the vault. <strong>Required</strong> whenever you change your embedding model or provider to ensure your index remains compatible.</td></tr><tr><td style="text-align:left;"><strong>Embedding dimension</strong></td><td style="text-align:left;"><code>768</code></td><td style="text-align:left;">Must match your chosen model. <br>‚ö†Ô∏è <strong>Warning:</strong> Changing this wipes your index.</td></tr><tr><td style="text-align:left;"><strong>Minimum similarity score</strong></td><td style="text-align:left;"><code>0.5</code></td><td style="text-align:left;">Relevance threshold. Matches below this score are ignored. <br>‚Ä¢ <strong>Higher (0.7+):</strong> Strict. <br>‚Ä¢ <strong>Lower (0.35):</strong> Loose.</td></tr><tr><td style="text-align:left;"><strong>Similar notes limit</strong></td><td style="text-align:left;"><code>20</code></td><td style="text-align:left;">Max matches in the sidebar.</td></tr><tr><td style="text-align:left;"><strong>Vault search results limit</strong></td><td style="text-align:left;"><code>25</code></td><td style="text-align:left;">Max notes the Agent can retrieve (&quot;read&quot;) for any single question.</td></tr></tbody></table><h2 id="‚öôÔ∏è-advanced-hardware" tabindex="-1">‚öôÔ∏è Advanced &amp; Hardware <a class="header-anchor" href="#‚öôÔ∏è-advanced-hardware" aria-label="Permalink to &quot;‚öôÔ∏è Advanced &amp; Hardware&quot;">‚Äã</a></h2><table tabindex="0"><thead><tr><th style="text-align:left;">Setting</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Local embedding threads</strong></td><td style="text-align:left;"><code>1</code> (Mobile) / <code>2</code> (Desktop)</td><td style="text-align:left;">Only relevant for the <strong>Local</strong> provider. Number of CPU threads used for calculations. Higher is faster but uses more memory/battery.</td></tr><tr><td style="text-align:left;"><strong>Indexing delay (ms)</strong></td><td style="text-align:left;"><code>5000ms</code></td><td style="text-align:left;">The debounce delay for user edits. The plugin waits this long after your last keystroke before re-indexing the current note. High values prevent &quot;spamming&quot; your API quota or CPU while typing.</td></tr><tr><td style="text-align:left;"><strong>Bulk indexing delay (ms)</strong></td><td style="text-align:left;"><code>300ms</code></td><td style="text-align:left;">The delay between individual files during bulk operations (like a full vault scan). Keeps the system responsive and respects API rate limits during large updates.</td></tr><tr><td style="text-align:left;"><strong>Gemini retries</strong></td><td style="text-align:left;"><code>10</code></td><td style="text-align:left;">Automatic retries for spotty connections.</td></tr><tr><td style="text-align:left;"><strong>System instruction</strong></td><td style="text-align:left;"><em>Default Persona</em></td><td style="text-align:left;">The core personality and rules for the Agent.</td></tr><tr><td style="text-align:left;"><strong>Log level</strong></td><td style="text-align:left;"><code>Warn</code></td><td style="text-align:left;">Developer console verbosity. Set to <code>Debug</code> to see detailed &quot;Chain of Thought&quot;.</td></tr></tbody></table><hr><h2 id="üÜö-gemini-vs-local-models" tabindex="-1">üÜö Gemini vs. Local Models <a class="header-anchor" href="#üÜö-gemini-vs-local-models" aria-label="Permalink to &quot;üÜö Gemini vs. Local Models&quot;">‚Äã</a></h2><p>Choosing the right embedding provider involves balancing privacy, performance, and accuracy.</p><h3 id="‚òÅÔ∏è-google-gemini-cloud" tabindex="-1">‚òÅÔ∏è Google Gemini (Cloud) <a class="header-anchor" href="#‚òÅÔ∏è-google-gemini-cloud" aria-label="Permalink to &quot;‚òÅÔ∏è Google Gemini (Cloud)&quot;">‚Äã</a></h3><p><strong>Ideal for:</strong> Users with reliable internet who want the highest possible retrieval quality.</p><ul><li><strong>Pros:</strong> State-of-the-art accuracy (<code>gemini-embedding-004</code>), zero local CPU/RAM overhead for embeddings, handles large documents gracefully.</li><li><strong>Cons:</strong> Requires an API key, subject to remote rate limits, notes are processed by Google (though not used for training per their AI Studio terms).</li></ul><h3 id="üíª-transformers-js-local" tabindex="-1">üíª Transformers.js (Local) <a class="header-anchor" href="#üíª-transformers-js-local" aria-label="Permalink to &quot;üíª Transformers.js (Local)&quot;">‚Äã</a></h3><p><strong>Ideal for:</strong> Privacy-conscious users, offline use, or those wanting to avoid API rate limits.</p><ul><li><strong>Pros:</strong> 100% private and offline, no API costs or rate limits, works with any ONNX-compatible model.</li><li><strong>Cons:</strong> Uses local CPU/RAM (can slow down older devices), slightly lower retrieval quality on the smallest presets.</li></ul><table tabindex="0"><thead><tr><th style="text-align:left;">Model Preset</th><th style="text-align:left;">Quality</th><th style="text-align:left;">Speed</th><th style="text-align:left;">Local RAM</th><th style="text-align:left;">Recommendation</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Gemini 004</strong></td><td style="text-align:left;">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td><td style="text-align:left;">‚ö°‚ö°‚ö°</td><td style="text-align:left;">0MB</td><td style="text-align:left;">Best for deep research.</td></tr><tr><td style="text-align:left;"><strong>Nomic-Embed</strong></td><td style="text-align:left;">‚≠ê‚≠ê‚≠ê‚≠ê</td><td style="text-align:left;">‚ö°‚ö°</td><td style="text-align:left;">~150MB</td><td style="text-align:left;">Best local quality.</td></tr><tr><td style="text-align:left;"><strong>BGE-Small</strong></td><td style="text-align:left;">‚≠ê‚≠ê‚≠ê</td><td style="text-align:left;">‚ö°‚ö°‚ö°</td><td style="text-align:left;">~40MB</td><td style="text-align:left;">For general use.</td></tr><tr><td style="text-align:left;"><strong>Potion-8M</strong></td><td style="text-align:left;">‚≠ê‚≠ê</td><td style="text-align:left;">‚ö°‚ö°‚ö°‚ö°</td><td style="text-align:left;">~15MB</td><td style="text-align:left;">Best for mobile/older PCs.</td></tr></tbody></table>',21)])])}const y=e(r,[["render",s]]);export{f as __pageData,y as default};
