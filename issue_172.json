{"body":"\n\n### **Executive Summary**\n\nWe are planning a fundamental architectural shift for the search and discovery engine (\"Explorer\" and \"Researcher\"). We are moving away from **mathematical heuristics** (tuning sliders to guess relevance) to **AI reasoning** (using Gemini 3 to judge relevance).\n\nThis change aims to solve the \"Fragile Search\" problem where users must manually tune 15+ complex settings just to make the plugin find their notes.\n\n---\n\n### **1. The Situation (The Problem)**\n\nCurrently, Vault Intelligence relies on a \"House of Cards\" made of math. To decide if a note is relevant, we multiply arbitrary numbers: `Vector Score (0.6) * User Weight (0.2) > Threshold (0.35)`.\n\n* **It is Fragile:** If you tweak one slider to fix a specific search, you often break five others.\n* **It is \"Dumb\":** The system cannot distinguish between a *lexical* match and a *semantic* match.\n* *Example:* Searching for **\"Cat\"** might rank a note about **\"Catholicism\"** at the top (because it contains the letters c-a-t), while burying a story about your pet **\"Bartholomew\"** (because the math penalized the graph connection too heavily).\n\n\n* **The Burden:** Users are currently forced to act as \"Search Engineers,\" tweaking floating-point numbers to get the system to behave.\n\n### **2. The Opportunity (The Solution)**\n\nWe are introducing **Vault Intelligence v4.0**, utilizing a \"Dual-Loop\" architecture that separates *speed* from *intelligence*.\n\n* **Loop 1: The Reflex (Instant)**\n* A parameter-free local search that runs on your device.\n* It gives you immediate, high-recall results (like a standard search engine) without waiting for the cloud.\n* *Benefit:* It works 100% offline and feels instantaneous.\n\n\n* **Loop 2: The Analyst (Intelligent)**\n* Asynchronously sends your top results to **Gemini 3**.\n* The AI acts as a \"Librarian\" that reads the list and **re-ranks** it based on your intent.\n* *Benefit:* It can filter out noise (hiding \"Catholicism\" when you want pets) and \"rescue\" deep connections (pulling \"Bartholomew\" to the top) without you ever touching a slider.\n\n\n\n**The Goal:** A \"Zero-Config\" experience. The search just works, adapting to whether you are exploring concepts or looking for specific facts.\n\n### **3. The Complications (Challenges to Solve)**\n\nImplementing this \"Smart Search\" introduces new UX challenges we need to manage carefully:\n\n* **The \"Pop-in\" Effect (Latency):**\n* Because the AI takes ~1 second to think, the \"Smart Results\" will arrive *after* the local results are already on screen.\n* *Risk:* The list might shuffle while you are trying to click something. We need a UI that updates smoothly (using animations or \"Insight Cards\") rather than jumping around unpredictably.\n\n\n* **Privacy & Offline Support:**\n* The \"Analyst\" requires an internet connection. We must ensure the \"Reflex\" (Local) loop is powerful enough to stand on its own when you are on a plane or in strict privacy mode.\n\n\n* **Trust & Visibility:**\n* If the AI decides to hide a result (like \"Catholicism\"), users might panic that the system is broken. We need to find ways to *dim* or *deprioritize* irrelevant results rather than deleting them entirely, so you always remain in control."}
